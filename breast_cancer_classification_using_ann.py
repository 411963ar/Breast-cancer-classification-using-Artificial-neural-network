# -*- coding: utf-8 -*-
"""Breast cancer classification using Ann.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OnhHA4wTk84lHZ1IUP4lgkJRmcsuU7nu

Breast cancer prediction using Artificial neural network
"""

#importing libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.datasets
from sklearn.model_selection import train_test_split

#Data Loading and Preprocessing

breast_cancer_dataset=sklearn.datasets.load_breast_cancer()

print(breast_cancer_dataset)

data_frame=pd.DataFrame(breast_cancer_dataset.data,columns= breast_cancer_dataset.feature_names)

data_frame.head(5)

data_frame['label']=breast_cancer_dataset.target

data_frame.tail(5)

data_frame['label'].value_counts()

data_frame.groupby('label').mean()

#separating features and targets in two different variables

x=data_frame.drop(columns='label',axis=1)

y=data_frame['label']

print(x)

print(y)

#splitting the data into train test splits

X_train,X_test,Y_train,Y_test= train_test_split(x,y,test_size=0.2,random_state=2)

"""stardizing the data"""

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler() #loading the standard scaler function into the variable scaler
X_train_std= scaler.fit_transform(X_train) #fit transform function is a combination of fit and transform,fit will learn parameters like mean,standard deviation from data and then transform in into standardize values,all values in same range.
X_test_std= scaler.transform(X_test) #we dont use fit with test data because we dont want the model to train from data we use for testing,we want it to be unseen

print(X_train_std)
print(X_test_std)

print(x.shape,X_train.shape,X_test.shape)

#Building a neural network

import tensorflow as tf #importing tensor flow library

tf.random.set_seed(3) #we set random seed to initialize neural network with random weights and bias,each time the neural network runs,it give different accuracy,to avoid this the random seed will help,after setting this no matter how many times u run neural network,u will have same accuracy every time

from tensorflow import keras # importing keras from tensor flow

#setting layers of neural network

model= keras.Sequential([keras.layers.Flatten(input_shape=(30,)), # converting features into single dimention
                         keras.layers.Dense(20,activation='relu'), # 20 neurons in hidden layer,Dense means fully connected neural network
                         keras.layers.Dense(2,activation='sigmoid')]) #2 classes so 2 neurons in output layers

# compiling the neural network

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

#training the model

history=model.fit(X_train_std,Y_train,validation_split=0.1,epochs=10) #epoch means iteration,validation split means how much data from training to use for testing/validation

"""Visualizing accuracy and loss"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training data','validation data'],loc= 'lower right')

plt.plot(history.history['loss'])
 plt.plot(history.history['val_loss'])
 plt.title('model loss')
 plt.ylabel('loss')
 plt.xlabel('epoch')
 plt.legend(['training data,validation data'],loc='lower right')

"""Testing the accuracy of the model on test data"""

loss,accuracy= model.evaluate(X_test_std,Y_test)
print(accuracy)

print(X_test_std.shape)

print(X_test_std[0]) #first data point

y_pred=model.predict(X_test_std)

print(y_pred.shape)

print(y_pred[0])

print(y_pred) # these are probabi;itites of each datapoint,like 0.89 means 89 percent probability that it belongs to class 1 and 0.12 means 12 percent probability of belonging to class 0

